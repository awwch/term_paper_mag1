# -*- coding: utf-8 -*-
"""
Created on Mon Jul 25 12:53:41 2016

@author: cogntech
"""
import json
import os
import nltk
from nltk.corpus import stopwords
import pymorphy2
import pandas as pd
import re
from collections import Counter

def str_key (_dict):
    key = (str(list(_dict.keys())).strip('[]')).replace("'",'')
    return(key)
def str_value (_dict): 
    value = (str(list(_dict.values())).strip('[]')).replace("'",'')
    return(value)

stop_words = stopwords.words('russian')
stop_words.extend(["тка","ка","например", "также", "нибудь", "который", "свой", "обычно", "некоторый", "кому"])
morph = pymorphy2.MorphAnalyzer()
tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')
_dict = pd.read_csv(os.getcwd()+"\\ozhegov2_ex.csv", header=0, delimiter=";")

def dict_to_wordlist(text, remove_stopwords=True):
    words = []
    gram_info = []
    text = re.sub("[^а-яА-Я]"," ", text)
    all_words = text.lower().split()
    for word in all_words:
        p = morph.parse(word)[0]
        if word not in stop_words and  p.normal_form not in stop_words:
            words.append({word:p.normal_form})
            gram_info.append({p.normal_form:str(p.tag)})
    return(words,gram_info)
    
def dict_to_sentences(text,tokenizer, remove_stopwords=True):
    raw_sentences = tokenizer.tokenize(text.strip())
    sentences = []
    for raw_sentence in raw_sentences:
        if dict_to_wordlist(raw_sentence,remove_stopwords) not in sentences:
            sentences.append(dict_to_wordlist(raw_sentence,remove_stopwords))
    return(sentences)

sentences = []
baseforms = []
words = []
voc = []
i = 0
for art in _dict["DEF"]:
    voc.append(_dict["VOCAB"][i])
    #words.append({i:_dict["VOCAB"][i]})
    #art = _dict["VOCAB"][i]+ ' ' + str(art)
    #baseforms.append(_dict["BASEFORM"][i])
    #sentences.append(dict_to_sentences(str(art), tokenizer))
    i += 1
    
voc_tags = []
for word in voc:
    p = morph.parse(word)[0]
    word = {word:str(p.tag)}
    voc_tags.append(word)
    
### ОМОНИМИЯ:
omonymy = []
omonymy_indx = []
om_counter = []
sim_w_counter = []
for i in range(len(baseforms)):
    if baseforms[i] >= 1:
        om_counter.append(int(baseforms[i]))
    else:
        om_counter.append(0) 
    omonymy_indx.append({str_key(words[i])+ ' ' +(str_value(words[i])):om_counter[i]})
    omonymy.append({str_value(words[i]):om_counter[i]})
    c = words.count(str_value(words[i]))
    #if {str_value(words[i]):c} not in sim_w_counter:    
     #  sim_w_counter.append({str_value(words[i]):c})

###ИМПОРТ В JSON:
# добавить стоп-слова
to_json = []
with open('ozhegov_data.json','w',encoding = 'utf-8') as outfile:
    for i in range(len(sentences)):
        for s in sentences[i]:
            s = list(s)
            s[0] = {'LEMMAS':s[0]}
            s[-1] = {'GRAM':s[-1]}
            to_json.append({str(voc_tags[i]) + '; ' + str(om_counter[i]):s})
    json.dump(to_json,outfile,ensure_ascii=False,indent=1)

###ПОИСК ПО ГРАМ. ТЕГАМ:
with open("ozhegov_data.json",encoding = 'utf-8') as json_file:
    json_data = json.load(json_file, encoding= 'utf-8' )

#result = []
#k_word = 'болезнь'

mistakes = []
wrong_nouns = []
for line in json_data:
    defin = line.values()
    tags = []
    main_w = line.keys()
    d = list(main_w)[0].replace(';','')
    d = d.strip(d[-1])
    d = eval(d.strip(' '))
    m = re.match('NOUN',list(d.values())[0])
    if m != None:
        for _def in defin:
            nouns= []
            gram = list(_def[-1].values())[-1]
            for _dict in gram:
                m = re.match('NOUN',list(_dict.values())[0])
                if m != None:
                    nouns.append(_dict)
                for noun in nouns:
                    m = re.match('NOUN.+accs', str_value(noun))
                    if m != None and nouns.index(noun) == 0:
                        if line not in mistakes:
                            mistakes.append(line)
                    #if k_word == str_key(noun):
                     #   if str_key(line)+ '; ' + str(json_data.index(line)) not in result:
                      #      result.append(str_key(line)+ '; ' + str(json_data.index(line)))
#wrong_n = []
for mistake in mistakes:
    if mistake in json_data:
        indx = json_data.index(mistake)
        #json_data.remove(mistake)
        defin = mistake.values()
        nouns= []
        for _def in defin:
            gram = list(_def[-1].values())[-1]
            for _dict in gram:
                m = re.match('NOUN',list(_dict.values())[0])
                if m != None:
                    nouns.append(_dict)
                for noun in nouns:
                    m = re.match('NOUN.+accs', str_value(noun))
                    if m != None and nouns.index(noun) == 0:
                        #if noun not in wrong_n:
                            #wrong_n.append(noun)
                        fine_gram = str_value(noun).replace('accs','nomn')
                        fine_noun = {str_key(noun):fine_gram}
                        indx = gram.index(_dict)
                        #indx = nouns.index(noun)
                        #nouns.remove(noun)
                        #nouns.insert(indx,fine_noun)
        



result = []
k_word = 'болезнь'
for line in json_data:
    defin = line.values()
    voc = list(line.keys())[0].split(';')[0]
    tags = []
    for _def in defin:
        gram = _def[-1]
        for word in list(gram.values())[-1]:
            number = list(gram.values())[-1].index(word)
            tags.append(str_value(word))
            if str_key(word) == k_word:
                for tag in tags:
                    m = re.match('NOUN',tag)
                    #m = re.match('INFN',tags)
                    if m != None and tags.index(tag) == number:#and {k_word:tag} in list(gram.values())#and tags.index(tag) == number and number <= 5:
                        result.append(str_key(line)+ '; ' + str(json_data.index(line)))
with open(k_word+'.txt','w',encoding = 'utf-8') as f:
    for r in result:
        f.write(r + '\n')
f.close()

#####################################
#rep_count_try = []
#for i in range(len(omonymy)):

rep_count = []
for o in omonymy:
    c = omonymy.count(o)
    if {str_key(o):c} not in rep_count:
        rep_count.append({str_key(o):c})

rep_lines = []
repetitions = []
for rep in rep_count:
    repetitions.append(int(str_value(rep)))
rep_lines = []
for rep in rep_count:
    rep_lines.append(str_key(rep))
    
final = []
for n in range(len(rep_count)):
    for i in range(int(str_value(rep_count[n]))):
        final.append({str_key(rep_count[n]):i+1})
#####################################################

###### СРАВНКЕНИЕ ИНДЕКСОВ
all_words = []
i = 0
for w in words:
    all_words.append({str_value(w):i})
    i+=1
    
counter = []
for i in range(len(rep_count)):
    count = int(str_value(rep_count[i]))
    for c in range(count):
        if c == 0:
            counter.append({str_key(rep_count[i]):1})
        else:
            counter.append({str_key(rep_count[i]):c + 1}) 

counted_words = []        
for c in counter:
    counted_words.append(str_key(c))

count_indx = []
i = 0
for w in counted_words:
    count_indx.append(str(i) + ' ' + w)
    i+=1

for i in range(len(count_indx)):
    for j in range(len(omonymy_indx)):
        if str_key():
            
            

### ГИПЕРОНИМЫ В ТОЛКОВАНИИ
#c = Counter(nouns).most_common()
#v = Counter(inf).most_common()

### 1-е сущ
#for _class in c[:20]:
  #  f = open(_class[0]+'.txt','a',encoding = 'utf-8')    
   # for sentence in sentences:
    #    m = re.search(_class[0] + '.*NOUN.*nomn', str(sentence[-1])) #регулярка неоч
     #   if m != None:
      #      for s in sentence:
       #         f.write(str_key(s[0]) + '\n')
    #f.close()

### 1-й глагол 
#for verb in v[:20]:
 #   f=  open(verb[0] +'.txt','a',encoding = 'utf-8')
  #  for sentence in sentences:
   #     m = re.search(verb[0], str(sentence[-1]))
    #    
     #   if m != None:
      #      for s in sentence:
       #         f.write(str_key(s[0]) + '\n')            
    #f.close()


#####################################################
result = []
for line in json_data:
    m = re.match('специалист' + '.*NOUN.*nomn', str(line))
    if m != None:
        result.append(str_key(line) + '; ' + str(json_data.index(line)))
with open('специалист_2.txt','w',encoding = 'utf-8') as f:
    for r in result:
        f.write(r + '\n')
f.close()

#########################################################
result = []
k_word = 'материал'
for line in json_data:
    defin = line.values()
    voc = list(line.keys())[0].split(';')[0]
    tags = []
    for _def in defin:
        gram = _def[-1]
        for word in list(gram.values())[-1]:
            #number = list(gram.values())[-1].index(word)
            tags.append(str_value(word))
            if str_key(word) == k_word and list(gram.values())[-1].index(word) <= 2:
                for tag in tags:
                    m = re.match('NOUN.+nomn',tag)
                    #m = re.match('INFN',tags)
                    if m != None: #and tags.index(tag) == list(gram.values())[-1].index(word) and list(gram.values())[-1].index(word) <= 3:
                        result.append(str_key(line)+ '; ' + str(json_data.index(line)))

##########################################################
##########################################################
##########################################################
